{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1e6230-1dd8-4897-a8f6-2995143f5c83",
   "metadata": {},
   "source": [
    "## Memory constraint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2286ea2d-7065-45e1-abbc-8ba6eb113bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "#from albumentations.pytorch import ToTensor \n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import sklearn\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    " \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47745e5f-dc50-4d80-800d-9e6abdba7f79",
   "metadata": {},
   "source": [
    "### Load & Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144b9546-7fef-4acd-bb03-fccced7da370",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfake_types = ['Deepfakes', 'Face2Face', 'FaceShifter','FaceSwap', 'NeuralTextures' ]\n",
    "IMG_SIZE = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "BATCH_SIZE = 64\n",
    "device = 'cuda'\n",
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "class ImageTransform:\n",
    "    def __init__(self, size, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "                transforms.Resize((size, size), interpolation=Image.BILINEAR),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n",
    "    \n",
    "def load_dataset(DEEPFAKE_TYPE):\n",
    "    transformer = ImageTransform(IMG_SIZE, mean, std)\n",
    "\n",
    "    TRAIN_FOLDER = fr'D:\\FF\\crops\\{DEEPFAKE_TYPE}\\train' \n",
    "    VAL_FOLDER = fr'D:\\FF\\crops\\{DEEPFAKE_TYPE}\\val' \n",
    "    TEST_FOLDER = fr'D:\\FF\\crops\\{DEEPFAKE_TYPE}\\test' \n",
    "\n",
    "    train_ds = ImageFolder(root=TRAIN_FOLDER, transform=transformer)\n",
    "    val_ds = ImageFolder(root=VAL_FOLDER, transform=transformer)\n",
    "    test_ds = ImageFolder(root=TEST_FOLDER, transform=transformer)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, shuffle=True, batch_size=64)\n",
    "    val_loader = DataLoader(val_ds, shuffle=True, batch_size=64)\n",
    "    test_loader = DataLoader(test_ds, shuffle=False, batch_size=64)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def load_datasets(deepfake_types):\n",
    "    deepfake_datasets = {}\n",
    "    for deepfake_type in deepfake_types:\n",
    "        train_loader, val_loader, test_loader = load_dataset(deepfake_type)\n",
    "        deepfake_datasets[deepfake_type] = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "    return deepfake_datasets\n",
    "\n",
    "deepfake_datasets = load_datasets(deepfake_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f540f9e1-4aac-4e4a-badf-c6f0dd748a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(deepfake_datasets, initial='clients'):\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, deepfake_type) for deepfake_type in deepfake_types]\n",
    "    #shard data and place at each client. each shard is a different deepfake type\n",
    "    shards = deepfake_datasets\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {'{}_{}'.format(initial, deepfake_type) : shards[deepfake_type] for deepfake_type in deepfake_types}\n",
    "\n",
    "clients = create_clients(deepfake_datasets, initial='client')\n",
    "clients_batched = clients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960271b9-7a50-42d8-a787-db13fe5532ae",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61af8fcd-22ef-482e-afa3-30852aeed001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes,only_digits=True):\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=1)\n",
    "        return model\n",
    "\n",
    "def weight_scaling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = clients_trn_data[client_name].batch_size\n",
    "    #first calculate the total training data points across clients\n",
    "    global_count = sum([len(clients_trn_data[client_name]) for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count =  len(clients_trn_data[client_name]) * bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight_dict, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    for key in weight_dict:\n",
    "        weight_dict[key] *= scalar  # Scale weights in-place\n",
    "    return weight_dict\n",
    "\n",
    "def scale_model_weights2(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = torch.sum(torch.stack(grad_list_tuple), dim=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model_mid(model, test_loader, loss_fn):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = loss_fn\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Model forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Ensure outputs and labels have the same shape\n",
    "            outputs = outputs.view(-1)  # Flatten outputs to match labels\n",
    "            labels = labels.view(-1).float()  # Flatten labels and convert to float\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate predictions and accuracy\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            correct += (predictions == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    print('acc: {:.3%} | loss: {}'.format(accuracy, avg_loss))\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_model(model, test_loader, loss_fn):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = loss_fn\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Model forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Ensure outputs and labels have the same shape\n",
    "            outputs = outputs.view(-1)  # Flatten outputs to match labels\n",
    "            labels = labels.view(-1).float()  # Flatten labels and convert to float\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate predictions and accuracy\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            correct += (predictions == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    print('acc: {:.3%} | loss: {}'.format(accuracy, avg_loss))\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_dataset():\n",
    "    transformer = ImageTransform(IMG_SIZE, mean, std)\n",
    "    train_datasets = []\n",
    "    val_datasets = []\n",
    "    test_datasets = []\n",
    "    for deepfake_type in deepfake_types:\n",
    "        TRAIN_FOLDER = fr'D:\\FF\\crops\\{deepfake_type}\\train' \n",
    "        VAL_FOLDER = fr'D:\\FF\\crops\\{deepfake_type}\\val' \n",
    "        TEST_FOLDER = fr'D:\\FF\\crops\\{deepfake_type}\\test' \n",
    "\n",
    "        train_ds = ImageFolder(root=TRAIN_FOLDER, transform=transformer)\n",
    "        val_ds = ImageFolder(root=VAL_FOLDER, transform=transformer)\n",
    "        test_ds = ImageFolder(root=TEST_FOLDER, transform=transformer)\n",
    "\n",
    "        train_datasets.append(train_ds)\n",
    "        val_datasets.append(val_ds)\n",
    "        test_datasets.append(test_ds)\n",
    "    full_train_ds = ConcatDataset(train_datasets)\n",
    "    full_val_ds = ConcatDataset(val_datasets)\n",
    "    full_test_ds = ConcatDataset(test_datasets)\n",
    "    train_loader = DataLoader(full_train_ds, shuffle=True, batch_size=64)\n",
    "    val_loader = DataLoader(full_val_ds, shuffle=True, batch_size=64)\n",
    "    test_loader = DataLoader(full_test_ds, shuffle=False, batch_size=64)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a9aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 5\n",
    "MODEL_NAME = f'ff_effnet0_1fc_fl'\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, history, filename=MODEL_NAME):\n",
    "    checkpoint = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"history\": history,\n",
    "    }\n",
    "    filepath = f\"{filename}.pth\"\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved to {filepath}\")\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=PATIENCE, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = float('inf')  # Initialize to positive infinity\n",
    "        self.verbose = verbose\n",
    "    def best_val(self, val_loss):\n",
    "        if val_loss < self.best_score:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return False\n",
    "    def early_stop(self):\n",
    "        if self.counter >= self.patience:\n",
    "            if self.verbose:\n",
    "                print(\"Early stopping...\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def train(epochs, optimizer, model, train_loader, val_loader):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    val_loss_history = []\n",
    "    val_accuracy_history = []\n",
    "    for epoch in range(epochs): \n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.train()\n",
    "        for data, labels in train_loader:\n",
    "            data = data.squeeze(0)\n",
    "            labels = labels.squeeze(0)\n",
    "            labels = labels.to(device).float()\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()  # clear previous gradients\n",
    "\n",
    "            #data = data.to(device).float()\n",
    "            outputs = model(data).squeeze()\n",
    "            losses = loss_fn(outputs, labels)\n",
    "            running_loss += losses.item()  # accumulate loss\n",
    "            \n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            predicted   = (torch.sigmoid(outputs) >= 0.5).float() # calculate if label is 0 or 1\n",
    "            correct += (predicted == labels).sum().item() \n",
    "            total += labels.size(0)\n",
    "            train_loss_history.append(losses.item())\n",
    "\n",
    "        average_train_loss = running_loss / total\n",
    "        average_train_accuracy = correct / total\n",
    "        train_loss_history.append(average_train_loss)\n",
    "        train_accuracy_history.append(average_train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0 \n",
    "        for data, labels in val_loader:\n",
    "            data = data.squeeze(0)\n",
    "            labels = labels.squeeze(0)\n",
    "            labels = labels.to(device).float()\n",
    "            data = data.to(device).float()\n",
    "\n",
    "            outputs = model(data).squeeze()\n",
    "            losses = loss_fn(outputs, labels)\n",
    "            running_loss += losses.item()  # accumulate loss\n",
    "            predicted = (torch.sigmoid(outputs) >= 0.5).float() # calculate if label is 0 or 1\n",
    "            correct += (predicted == labels).sum().item() \n",
    "            total += labels.size(0)\n",
    "        average_val_loss = running_loss / total\n",
    "        average_val_accuracy = correct / total\n",
    "        val_loss_history.append(average_val_loss)\n",
    "        val_accuracy_history.append(average_val_accuracy)\n",
    "        print(f\"Epoch [{epoch}/{epochs}], Train Loss: {average_train_loss:.5f}, Train Accuracy: {average_train_accuracy:.5f}, Val Loss: {average_val_loss:.5f}, Val Accuracy: {average_val_accuracy:.5f}\")\n",
    "\n",
    "        \n",
    "    return train_loss_history, val_loss_history, train_accuracy_history, val_accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42cf8f-17a7-4039-aab8-9799d4e2d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "0 comm\n",
      "client_Deepfakes\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00615, Train Accuracy: 0.83825, Val Loss: 0.00495, Val Accuracy: 0.86478\n",
      "Epoch [1/2], Train Loss: 0.00488, Train Accuracy: 0.86951, Val Loss: 0.00456, Val Accuracy: 0.87573\n",
      "acc: 85.809% | loss: 0.3292569801372161\n",
      "client_Face2Face\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00794, Train Accuracy: 0.75865, Val Loss: 0.00689, Val Accuracy: 0.80225\n",
      "Epoch [1/2], Train Loss: 0.00702, Train Accuracy: 0.78906, Val Loss: 0.00654, Val Accuracy: 0.81229\n",
      "acc: 79.548% | loss: 0.4380661367837872\n",
      "client_FaceShifter\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00767, Train Accuracy: 0.77631, Val Loss: 0.00662, Val Accuracy: 0.81881\n",
      "Epoch [1/2], Train Loss: 0.00660, Train Accuracy: 0.81097, Val Loss: 0.00622, Val Accuracy: 0.82804\n",
      "acc: 82.011% | loss: 0.3970534025872354\n",
      "client_FaceSwap\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00710, Train Accuracy: 0.79575, Val Loss: 0.00585, Val Accuracy: 0.83264\n",
      "Epoch [1/2], Train Loss: 0.00609, Train Accuracy: 0.82731, Val Loss: 0.00535, Val Accuracy: 0.85336\n",
      "acc: 83.837% | loss: 0.3585553439866219\n",
      "client_NeuralTextures\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00817, Train Accuracy: 0.74669, Val Loss: 0.00717, Val Accuracy: 0.79306\n",
      "Epoch [1/2], Train Loss: 0.00736, Train Accuracy: 0.77596, Val Loss: 0.00696, Val Accuracy: 0.79723\n",
      "acc: 78.700% | loss: 0.4588330933462373\n",
      "global\n",
      "acc: 50.101% | loss: 375582.08995616005\n",
      "1 comm\n",
      "client_Deepfakes\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00593, Train Accuracy: 0.83509, Val Loss: 0.00519, Val Accuracy: 0.85484\n",
      "Epoch [1/2], Train Loss: 0.00530, Train Accuracy: 0.85145, Val Loss: 0.00490, Val Accuracy: 0.86432\n",
      "acc: 85.021% | loss: 0.3431086844141535\n",
      "client_Face2Face\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00799, Train Accuracy: 0.74978, Val Loss: 0.00726, Val Accuracy: 0.78162\n",
      "Epoch [1/2], Train Loss: 0.00746, Train Accuracy: 0.77356, Val Loss: 0.00697, Val Accuracy: 0.79143\n",
      "acc: 78.177% | loss: 0.45893885030278136\n",
      "client_FaceShifter\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00747, Train Accuracy: 0.77631, Val Loss: 0.00668, Val Accuracy: 0.80946\n",
      "Epoch [1/2], Train Loss: 0.00682, Train Accuracy: 0.80038, Val Loss: 0.00666, Val Accuracy: 0.81126\n",
      "acc: 80.459% | loss: 0.42246081508535277\n",
      "client_FaceSwap\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00754, Train Accuracy: 0.76851, Val Loss: 0.00618, Val Accuracy: 0.81924\n",
      "Epoch [1/2], Train Loss: 0.00661, Train Accuracy: 0.80623, Val Loss: 0.00583, Val Accuracy: 0.83005\n",
      "acc: 82.151% | loss: 0.38783791243497817\n",
      "client_NeuralTextures\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00801, Train Accuracy: 0.75104, Val Loss: 0.00738, Val Accuracy: 0.77842\n",
      "Epoch [1/2], Train Loss: 0.00759, Train Accuracy: 0.76710, Val Loss: 0.00713, Val Accuracy: 0.79103\n",
      "acc: 78.014% | loss: 0.46879523145637925\n",
      "global\n",
      "acc: 50.484% | loss: 32287975.573741008\n",
      "2 comm\n",
      "client_Deepfakes\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00675, Train Accuracy: 0.80194, Val Loss: 0.00557, Val Accuracy: 0.84478\n",
      "Epoch [1/2], Train Loss: 0.00611, Train Accuracy: 0.82666, Val Loss: 0.00531, Val Accuracy: 0.85291\n",
      "acc: 84.009% | loss: 0.3708543455322012\n",
      "client_Face2Face\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00873, Train Accuracy: 0.71712, Val Loss: 0.00770, Val Accuracy: 0.76178\n",
      "Epoch [1/2], Train Loss: 0.00820, Train Accuracy: 0.74186, Val Loss: 0.00744, Val Accuracy: 0.77475\n",
      "acc: 76.222% | loss: 0.5006270576268435\n",
      "client_FaceShifter\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00793, Train Accuracy: 0.75720, Val Loss: 0.00706, Val Accuracy: 0.79369\n",
      "Epoch [1/2], Train Loss: 0.00725, Train Accuracy: 0.78549, Val Loss: 0.00730, Val Accuracy: 0.78502\n",
      "acc: 78.974% | loss: 0.45261712039974955\n",
      "client_FaceSwap\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00824, Train Accuracy: 0.73731, Val Loss: 0.00644, Val Accuracy: 0.80651\n",
      "Epoch [1/2], Train Loss: 0.00742, Train Accuracy: 0.77681, Val Loss: 0.00629, Val Accuracy: 0.81563\n",
      "acc: 80.477% | loss: 0.4252678391656705\n",
      "client_NeuralTextures\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00855, Train Accuracy: 0.72839, Val Loss: 0.00759, Val Accuracy: 0.76907\n",
      "Epoch [1/2], Train Loss: 0.00821, Train Accuracy: 0.74434, Val Loss: 0.00747, Val Accuracy: 0.77515\n",
      "acc: 77.215% | loss: 0.4844771281099148\n",
      "global\n",
      "acc: 49.483% | loss: 388410121.5071942\n",
      "3 comm\n",
      "client_Deepfakes\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00748, Train Accuracy: 0.77547, Val Loss: 0.00620, Val Accuracy: 0.82637\n",
      "Epoch [1/2], Train Loss: 0.00692, Train Accuracy: 0.79790, Val Loss: 0.00620, Val Accuracy: 0.83100\n",
      "acc: 81.600% | loss: 0.4180814545574806\n",
      "client_Face2Face\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00937, Train Accuracy: 0.68780, Val Loss: 0.00835, Val Accuracy: 0.74555\n",
      "Epoch [1/2], Train Loss: 0.00889, Train Accuracy: 0.70972, Val Loss: 0.00832, Val Accuracy: 0.74284\n",
      "acc: 73.626% | loss: 0.5567017335976873\n",
      "client_FaceShifter\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00847, Train Accuracy: 0.73371, Val Loss: 0.00854, Val Accuracy: 0.76813\n",
      "Epoch [1/2], Train Loss: 0.00792, Train Accuracy: 0.75668, Val Loss: 0.00719, Val Accuracy: 0.78615\n",
      "acc: 78.862% | loss: 0.47585256847975066\n",
      "client_FaceSwap\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00897, Train Accuracy: 0.70786, Val Loss: 0.00714, Val Accuracy: 0.78950\n",
      "Epoch [1/2], Train Loss: 0.00805, Train Accuracy: 0.75317, Val Loss: 0.00685, Val Accuracy: 0.79863\n",
      "acc: 78.611% | loss: 0.46127463643039973\n",
      "client_NeuralTextures\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00915, Train Accuracy: 0.70206, Val Loss: 0.00821, Val Accuracy: 0.74282\n",
      "Epoch [1/2], Train Loss: 0.00868, Train Accuracy: 0.72065, Val Loss: 0.00802, Val Accuracy: 0.75194\n",
      "acc: 74.730% | loss: 0.5167135404382678\n",
      "global\n",
      "acc: 49.516% | loss: 845190410.438849\n",
      "4 comm\n",
      "client_Deepfakes\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00829, Train Accuracy: 0.73724, Val Loss: 0.00714, Val Accuracy: 0.79824\n",
      "Epoch [1/2], Train Loss: 0.00773, Train Accuracy: 0.76412, Val Loss: 0.00707, Val Accuracy: 0.80208\n",
      "acc: 79.890% | loss: 0.45074927313722296\n",
      "client_Face2Face\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00983, Train Accuracy: 0.66145, Val Loss: 0.00895, Val Accuracy: 0.71105\n",
      "Epoch [1/2], Train Loss: 0.00940, Train Accuracy: 0.68027, Val Loss: 0.00888, Val Accuracy: 0.70541\n",
      "acc: 70.716% | loss: 0.5814811580947468\n",
      "client_FaceShifter\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00897, Train Accuracy: 0.71107, Val Loss: 0.00818, Val Accuracy: 0.75552\n",
      "Epoch [1/2], Train Loss: 0.00853, Train Accuracy: 0.72986, Val Loss: 0.00799, Val Accuracy: 0.75845\n",
      "acc: 74.677% | loss: 0.518474687775262\n",
      "client_FaceSwap\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00935, Train Accuracy: 0.68888, Val Loss: 0.00770, Val Accuracy: 0.76844\n",
      "Epoch [1/2], Train Loss: 0.00858, Train Accuracy: 0.72598, Val Loss: 0.00728, Val Accuracy: 0.78703\n",
      "acc: 76.554% | loss: 0.49551593214273454\n",
      "client_NeuralTextures\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00952, Train Accuracy: 0.68138, Val Loss: 0.00893, Val Accuracy: 0.70902\n",
      "Epoch [1/2], Train Loss: 0.00918, Train Accuracy: 0.69450, Val Loss: 0.00850, Val Accuracy: 0.72930\n",
      "acc: 72.222% | loss: 0.5485515491567927\n",
      "global\n",
      "acc: 49.269% | loss: 574720652.7607914\n",
      "5 comm\n",
      "client_Deepfakes\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00885, Train Accuracy: 0.71182, Val Loss: 0.00876, Val Accuracy: 0.74458\n",
      "Epoch [1/2], Train Loss: 0.00852, Train Accuracy: 0.72992, Val Loss: 0.00819, Val Accuracy: 0.76469\n",
      "acc: 76.491% | loss: 0.5144724040794716\n",
      "client_Face2Face\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.01031, Train Accuracy: 0.63171, Val Loss: 0.00965, Val Accuracy: 0.68501\n",
      "Epoch [1/2], Train Loss: 0.00992, Train Accuracy: 0.64843, Val Loss: 0.00958, Val Accuracy: 0.69346\n",
      "acc: 68.435% | loss: 0.6114343140806471\n",
      "client_FaceShifter\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00952, Train Accuracy: 0.68119, Val Loss: 0.00988, Val Accuracy: 0.72523\n",
      "Epoch [1/2], Train Loss: 0.00914, Train Accuracy: 0.70141, Val Loss: 0.00945, Val Accuracy: 0.72635\n",
      "acc: 71.009% | loss: 0.5785650890722549\n",
      "client_FaceSwap\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00981, Train Accuracy: 0.66272, Val Loss: 0.00850, Val Accuracy: 0.73601\n",
      "Epoch [1/2], Train Loss: 0.00917, Train Accuracy: 0.69495, Val Loss: 0.00824, Val Accuracy: 0.75876\n",
      "acc: 74.677% | loss: 0.539030267723969\n",
      "client_NeuralTextures\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [0/2], Train Loss: 0.00999, Train Accuracy: 0.65563, Val Loss: 0.00909, Val Accuracy: 0.70362\n",
      "Epoch [1/2], Train Loss: 0.00960, Train Accuracy: 0.67029, Val Loss: 0.00912, Val Accuracy: 0.70125\n",
      "acc: 69.377% | loss: 0.5937553702069701\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m avg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(comm_round\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 58\u001b[0m     avg\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mranking_acc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     59\u001b[0m avg\u001b[38;5;241m=\u001b[39mavg\u001b[38;5;241m/\u001b[39m(comm_round\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     60\u001b[0m ranking_acc_comp\u001b[38;5;241m.\u001b[39mappend(avg)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#create optimizer\n",
    "import copy\n",
    "comms_round = 10\n",
    "lr = 0.01\n",
    "loss=torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "global_model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=1)\n",
    "for param in global_model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Unfreeze the final fully connected layer\n",
    "for param in global_model._fc.parameters():\n",
    "    param.requires_grad = True\n",
    "global_model = global_model.to(device)\n",
    "\n",
    "_, _, test_batched = load_full_dataset()\n",
    "\n",
    "average_weights=copy.deepcopy(global_model.state_dict())\n",
    "\n",
    "ranking_acc_comp=list() \n",
    "\n",
    "for comm_round in range(comms_round):  \n",
    "    print(comm_round, 'comm')\n",
    "    scaled_local_weight_list = list()\n",
    "    client_names= list(clients_batched.keys())\n",
    "    ranking_acc=list()\n",
    "\n",
    "    for client in client_names:\n",
    "        print(client)\n",
    "        local_model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=1)\n",
    "        for param in local_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Unfreeze the final fully connected layer\n",
    "        for param in local_model._fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        global_weights = copy.deepcopy(global_model.state_dict())\n",
    "        local_model.load_state_dict(global_weights)\n",
    "        optimizer = torch.optim.Adam(local_model.parameters(), lr=LR)\n",
    "        local_model = local_model.to(device)\n",
    "        train_loader, val_loader, test_loader = clients_batched[client]['train'], clients_batched[client]['val'], clients_batched[client]['test']\n",
    "        train_loss_history, val_loss_history, train_accuracy_history, val_accuracy_history = train(2, optimizer, local_model, train_loader, val_loader)\n",
    "        weights=local_model.state_dict()\n",
    "        for key in weights:\n",
    "            average_weights[key] += weights[key]\n",
    "        \n",
    "        local_loss, local_acc = test_model(local_model, test_loader, loss_fn)\n",
    "        ranking_acc.append(local_acc)\n",
    "\n",
    "    for key in average_weights:\n",
    "        average_weights[key] = average_weights[key] / 5\n",
    "\n",
    "    #clear session to free memory after each communication round\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    ranking_acc.sort(reverse=True)\n",
    "    temp=0\n",
    "    avg=0\n",
    "    for i in range(comm_round):\n",
    "        avg+=ranking_acc[i]\n",
    "    avg=avg/(comm_round+1)\n",
    "    ranking_acc_comp.append(avg)\n",
    "\n",
    "\n",
    "    #update global model\n",
    "    global_model.load_state_dict(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    print('global')\n",
    "    global_acc, global_loss = test_model(global_model, test_loader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487be4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model.load_state_dict(average_weights)\n",
    "def save_checkpoint(model, optimizer, epoch, history, filename=MODEL_NAME):\n",
    "    checkpoint = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"history\": history,\n",
    "    }\n",
    "    filepath = f\"{filename}.pth\"\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved to {filepath}\")\n",
    "save_checkpoint(global_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d278b1-8d33-4e19-825a-17a794ecba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ranking_acc_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd5c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
